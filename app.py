# ========== app.py ==========

import streamlit as st
import requests
import joblib
import re
import os
import nltk
from nltk.corpus import stopwords

# ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¦Ù…Ø© ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙˆÙ‚Ù Ù„Ùˆ Ù„Ù… ØªÙƒÙ† Ù…Ø­Ù…Ù„Ø©
nltk.download('stopwords')

# ØªØ¹Ø±ÙŠÙ Ù…Ø¬Ù…ÙˆØ¹Ø© ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙˆÙ‚Ù Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
arabic_stopwords = set(stopwords.words('arabic'))

# ========== Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªÙˆÙƒÙ†Ø§Øª ==========
GROQ_API_KEY = os.getenv("GROQ_API_KEY")


# ========== ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨Ø© ==========
tfidf = joblib.load('tfidf_vectorizer.pkl')
label_encoder = joblib.load('label_encoder.pkl')
svm_model = joblib.load('svm_model.pkl')
lr_model = joblib.load('lr_model.pkl')


# ========== Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© ==========

# ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ
def clean_text(text):
    if not isinstance(text, str):
        return ''

    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„
    text = remove_tashkeel(text)
    
    # Ø¥Ø²Ø§Ù„Ø© Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ… ÙˆØ§Ù„Ø£Ø±Ù‚Ø§Ù…
    text = re.sub(r'[^\u0600-\u06FF\s]', ' ', text) 
    text = re.sub(r'[\d\u0660-\u0669]+', ' ', text)
    text = re.sub(r'[a-zA-Z]+', ' ', text)
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙØ±Ø§ØºØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
    text = re.sub(r'\s+', ' ', text).strip()
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„Ù…Ø¨Ø§Ù„Øº ÙÙŠÙ‡
    text = remove_repeated_chars(text)
    
    # Ø¥Ø²Ø§Ù„Ø© ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙˆÙ‚Ù
    tokens = text.split()
    tokens = [word for word in tokens if word not in arabic_stopwords]

    text = ' '.join(tokens)

    return text

def remove_tashkeel(text):
    tashkeel = re.compile(r'[\u0617-\u061A\u064B-\u0652]')
    return tashkeel.sub('', text)

def remove_repeated_chars(text):
    return re.sub(r'(.)\1{2,}', r'\1\1', text)

# Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø£Ø¹Ù„Ù‰ 3 ØªØµÙ†ÙŠÙØ§Øª
def predict_top3_with_model(text, model_name):
    cleaned = clean_text(text)
    vectorized = tfidf.transform([cleaned])

    if model_name == "Logistic Regression":
        probabilities = lr_model.predict_proba(vectorized)[0]
    else:
        probabilities = svm_model.predict_proba(vectorized)[0]

    top3_idx = probabilities.argsort()[-3:][::-1]
    top3_scores = probabilities[top3_idx]
    top3_labels = label_encoder.inverse_transform(top3_idx)

    percentages = (top3_scores * 100).round().astype(int)

    return list(zip(top3_labels, percentages))



# ØªÙ„Ø®ÙŠØµ ÙˆØ§Ù‚ØªØ±Ø§Ø­ Ø¹Ù†ÙˆØ§Ù† Ø¹Ø¨Ø± Groq API
def summarize_and_suggest_title(text):
    url = "https://api.groq.com/openai/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {GROQ_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "allam-2-7b",
        "messages": [
            {"role": "system", "content": "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ. Ø¹Ù†Ø¯Ù…Ø§ ÙŠØµÙ„Ùƒ Ù†Øµ Ø·ÙˆÙŠÙ„ØŒ Ù‚Ù… Ø¨ØªÙ„Ø®ÙŠØµÙ‡ Ø¨Ø´ÙƒÙ„ Ù…Ø®ØªØµØ±ØŒ Ø«Ù… Ø§Ù‚ØªØ±Ø­ Ø¹Ù†ÙˆØ§Ù†Ù‹Ø§ Ù‚ØµÙŠØ±Ù‹Ø§ ÙˆØ¬Ø°Ø§Ø¨Ù‹Ø§ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©."},
            {"role": "user", "content": f"Ù‡Ø°Ø§ Ù‡Ùˆ Ù†Øµ Ø§Ù„Ù…Ù‚Ø§Ù„:\n\n{text}\n\nØ±Ø¬Ø§Ø¡Ù‹: 1- Ù„Ø®Øµ Ø§Ù„Ù…Ù‚Ø§Ù„ ÙÙŠ ÙÙ‚Ø±Ø© Ù‚ØµÙŠØ±Ø©. 2- Ø§Ù‚ØªØ±Ø­ Ø¹Ù†ÙˆØ§Ù†Ù‹Ø§ Ø°ÙƒÙŠÙ‹Ø§ Ù„Ù„Ù…Ù‚Ø§Ù„."}
        ],
        "temperature": 0.5,
        "max_tokens": 500
    }
    response = requests.post(url, headers=headers, json=payload)
    if response.status_code == 200:
        reply = response.json()["choices"][0]["message"]["content"].strip()
        return reply
    else:
        return f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {response.status_code} - {response.text}"

# ØµÙØ­Ø© Ø­ÙˆÙ„ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
def show_about():
    st.markdown("""
    ## Ø­ÙˆÙ„ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ğŸ§ 
    Ù‡Ø°Ø§ Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠÙ‚ÙˆÙ… Ø¨ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª Ø§Ù„Ø¥Ø®Ø¨Ø§Ø±ÙŠØ© Ø§Ù„Ù…ÙƒØªÙˆØ¨Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.
    
    - **ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ù‚Ø§Ù„** Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… SVM & Logistic Regression.
    - **ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù…Ù‚Ø§Ù„ ÙˆØ§Ù‚ØªØ±Ø§Ø­ Ø¹Ù†ÙˆØ§Ù†** Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Groq - Allam 2 7B.
    
    ### 
    Ù…Ø´Ø±ÙˆØ¹ Ù„Ù…Ù‚Ø±Ø± EMAI 631 â€“ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© (NLP).
    """)

# ========== Ø¥Ø¹Ø¯Ø§Ø¯ ÙˆØ§Ø¬Ù‡Ø© Streamlit ==========

st.set_page_config(
    page_title="ØªØµÙ†ÙŠÙ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
    page_icon="ğŸ“°",
    layout="centered"
)

# ÙˆØ§Ø¬Ù‡Ø© RTL
st.markdown(
    """
    <style>
    body, .stApp {
        direction: rtl;
        text-align: right;
    }
    </style>
    """,
    unsafe_allow_html=True
)

st.title("ğŸ“° ØªØµÙ†ÙŠÙ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")

tabs = st.tabs(["ğŸ“° ØªØµÙ†ÙŠÙ ÙˆØªØ­Ù„ÙŠÙ„ Ù…Ù‚Ø§Ù„", "â„¹ï¸ Ø­ÙˆÙ„ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"])




# ======== Ø§Ù„ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø£ÙˆÙ„: ØªØµÙ†ÙŠÙ ÙˆØªØ­Ù„ÙŠÙ„ Ù…Ù‚Ø§Ù„ ========
with tabs[0]:
    st.subheader("ğŸ“„ Ø£Ø¯Ø®Ù„ Ù†Øµ Ø§Ù„Ù…Ù‚Ø§Ù„:")
    user_input = st.text_area("âœï¸ Ø§ÙƒØªØ¨ Ø£Ùˆ Ø§Ù„ØµÙ‚ Ù†Øµ Ø§Ù„Ù…Ù‚Ø§Ù„ Ù‡Ù†Ø§:", height=250)

    model_choice = st.selectbox(
    "Ø§Ø®ØªØ± Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØµÙ†ÙŠÙ",
    ("SVM", "Logistic Regression")
)

    if st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ù„"):
        if not user_input.strip():
            st.warning("âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ù†Øµ Ù‚Ø¨Ù„ Ø§Ù„ØªØµÙ†ÙŠÙ.")
        else:
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ø¯Ø§Ù„Ø© Ù…Ø¹ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            top3_predictions = predict_top3_with_model(user_input, model_choice)

            st.success("âœ… Ø£Ø¹Ù„Ù‰ 3 ØªØµÙ†ÙŠÙØ§Øª Ù…Ø­ØªÙ…Ù„Ø©:")
            for label, percent in top3_predictions:
                st.write(f"ğŸ”¹ {label}: {percent}%")

            st.markdown("---")
            st.success("ğŸ“ ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù…Ù‚Ø§Ù„ ÙˆØ§Ù‚ØªØ±Ø§Ø­ Ø¹Ù†ÙˆØ§Ù†:")
            result = summarize_and_suggest_title(user_input)
            st.write(result)


# ======== Ø§Ù„ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø«Ø§Ù†ÙŠ: Ø­ÙˆÙ„ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ========
with tabs[1]:
    show_about()

# ======== ØªØ°ÙŠÙŠÙ„ ========
st.markdown("---")
st.caption("  NLP Ù…Ø´Ø±ÙˆØ¹ Ù…Ù‚Ø¯Ù… Ù„Ù…Ù‚Ø±Ø± EMAI 631")
